{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "This file allows for a single image to be tested and debugged in order to adjust parameters and work on the OCR Script in a different environment without changing the original ipynb file.\n",
        "\n",
        "It also provides further visuals for the image, cropping out the regions of text it detects on the image.\n",
        "\n",
        "To use:\n",
        "1. Run the \"!pip install easyocr\" command in the first cell to setup the environment.\n",
        "2. In files, upload the image(s) that you want to run the code on.\n",
        "3. Set the IMAGE_PATH equal to the name of the file.\n",
        "4. Run the OCR Script and the output will be printed below the code cell."
      ],
      "metadata": {
        "id": "Ol2Dn3hz1As6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "id": "I8elIfJ00_7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = \"\"  # Enter path to your image here"
      ],
      "metadata": {
        "id": "tcUG5k3E2ZAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "anXsUWKvSade"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where the gamma, alpha, beta values can be adjusted to test different combinations on the image."
      ],
      "metadata": {
        "id": "i3i48BSh4iNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.5\n",
        "alpha = 1\n",
        "beta = 1"
      ],
      "metadata": {
        "id": "85Y4E_X-4NjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCR Testing Script"
      ],
      "metadata": {
        "id": "FrSzAWsG4pxG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja6iQ3Mk01oi"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import easyocr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import requests\n",
        "from difflib import get_close_matches\n",
        "from datetime import datetime\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def preprocess_image(image):\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray_equalized = cv2.equalizeHist(gray)\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \\\n",
        "                                        cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "    # Dilate the image\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    dilated = cv2.dilate(thresh, kernel, iterations=3)\n",
        "\n",
        "    # Detect edges using Canny edge detection\n",
        "    edges = cv2.Canny(dilated, 30, 150)\n",
        "\n",
        "    gamma_corrected = cv2.pow(gray_equalized / 255.0, gamma) # gamma\n",
        "    gamma_corrected = (gamma_corrected * 255).astype(np.uint8)\n",
        "\n",
        "    toned_down_img = cv2.convertScaleAbs(gamma_corrected, alpha, beta) #alpha, beta\n",
        "\n",
        "    return toned_down_img\n",
        "\n",
        "def download_english_words():\n",
        "    url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt\"\n",
        "    response = requests.get(url)\n",
        "    english_words = set(response.text.split())\n",
        "\n",
        "    return english_words\n",
        "\n",
        "def extract_text(image, image_path):\n",
        "\n",
        "    preprocessed_img = preprocess_image(image)\n",
        "\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    result = reader.readtext(image)\n",
        "\n",
        "    english_words = download_english_words()\n",
        "\n",
        "    # Specify structure shape and kernel size\n",
        "    rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))\n",
        "\n",
        "    # Applying dilation on threshhold image\n",
        "    dilation = cv2.dilate(preprocessed_img, rect_kernel, iterations = 1)\n",
        "\n",
        "    # Finding contours\n",
        "    contours, _ = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "    # Create a copy of the image\n",
        "    im2 = image.copy()\n",
        "\n",
        "    # Display bounding boxes around detected text\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    for contour in contours:\n",
        "      # Bounding box detection (using contour detection)\n",
        "      x, y, w, h = cv2.boundingRect(contour)\n",
        "      rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
        "\n",
        "      for detection in result:\n",
        "        # Bounding box coordainates (using text detection)\n",
        "        points = detection[0]\n",
        "        x, y, x1, y1 = points[0][0], points[0][1], points[2][0], points[2][1]\n",
        "        w, h = x1 - x, y1 - y\n",
        "\n",
        "        rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        # Crop the region from the original image\n",
        "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
        "        cropped_region = im2[y:y + h, x:x + w]\n",
        "\n",
        "        # Preprocessing on the cropped region\n",
        "        preprocessed_cropped_region = preprocess_image(cropped_region)\n",
        "\n",
        "        # Apply Harris Corner Detection\n",
        "        corners = cv2.cornerHarris(preprocessed_cropped_region, 2, 3, 0.04)\n",
        "\n",
        "        # Threshold for an optimal value\n",
        "        corners_thresh = 0.01 * corners.max()\n",
        "\n",
        "        # Find corner coordinates\n",
        "        corner_coords = np.argwhere(corners > corners_thresh)\n",
        "\n",
        "        # Draw corners on the original image\n",
        "        for corner in corner_coords:\n",
        "            cv2.circle(image, (x + corner[1], y + corner[0]), 3, (0, 0, 255), -1)\n",
        "\n",
        "        # Define structure shape and kernel size for each letter\n",
        "        rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))  # Adjust size as needed\n",
        "\n",
        "        # Apply morphological operations to enhance letter structure\n",
        "        morph_image = cv2.morphologyEx(preprocessed_cropped_region, cv2.MORPH_CLOSE, rect_kernel)\n",
        "\n",
        "        # Display the cropped region for visual inspection\n",
        "        plt.figure()\n",
        "        plt.imshow(preprocessed_cropped_region, cmap='gray')\n",
        "        plt.title(f\"Cropped Region for {image_path}\")\n",
        "        plt.show()\n",
        "\n",
        "        # Run EasyOCR on the cropped region\n",
        "        cropped_result = reader.readtext(preprocessed_cropped_region)\n",
        "\n",
        "        for cropped_detection in cropped_result:\n",
        "              # Find the closest English word\n",
        "              detected_text = detection[1].lower()\n",
        "              detected_text = detected_text.replace(\"[\", \"1\").replace(\"(\", \"1\")\n",
        "              closest_word = get_close_matches(detected_text, english_words, n=1)[0] if detected_text in english_words else 'N/A'\n",
        "\n",
        "              print(\"Extracted text:\", detected_text)\n",
        "              print(\"Closest word:\", closest_word)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    image = cv2.imread(IMAGE_PATH)\n",
        "    extract_text(image, IMAGE_PATH)\n"
      ]
    }
  ]
}